---
title: "Magnitude of degradation"
output: html_document
editor_options: 
  chunk_output_type: console
---


We expect that both direct and indirect indicators will have similar performance in describing the magnitude of degradation and predicting collapse. We will use two generalised linear mixed models (GLMM) to test if there are significant differences in inferences based on these estimates of relative severity.

For the combinations of units and models that did not reach a point of collapse, we wanted to compare the magnitude of degradation as indicated by the value of $\overline{\mathrm{RS}}$, $cED(0.25)$, $cED(0.25)$, $cED(0.25)$ and $AUC_{cED}$.


```{r}
#| label: load libraries and functions
#| eval: true
#| echo: false
#| warning: false
#| message: false
library(dplyr)
library(ggplot2)
library(units)
library(stringr)
library(ggrepel)
library(purrr)
library(readr)
library(tidyr)
library(glmmTMB)
library(lme4)
library(DHARMa)
here::i_am("docs-src/GLMM/beta-RS.qmd")
source(here::here("inc","R","RS-functions.R"))
source(here::here("inc","R","RS-shared.R"))
```

```{r}
#| label: read input data 
#| eval: true
#| message: false
target.dir <- "sandbox"
rds.file <- here::here(target.dir,"massbalance-totalmass-all-groups.rds")
totalmass_year_data <- readRDS(rds.file)
results_file <- here::here(target.dir, "relative-severity-degradation-suitability-all-tropical-glaciers.csv")
RS_results <- read_csv(results_file, show_col_types = FALSE) %>%
  mutate(unit_name=str_replace_all(unit," ","-"))
rds.file <- here::here(target.dir,"totalmass-suitability-glmm-data.rds")
model_data <- readRDS(rds.file)
rds.file <- here::here(target.dir,"totalmass-suitability-cED-data.rds")
cED_model_data <- readRDS(rds.file)

```


To compare both indicators we used the $RS_{bcs}^{CT=acc}$, $RS_{bcs}^{CT=ppv}$ and $RS_{bcs}^{CT=ess}$ for the future periods paired with the $RS_{ice}^{CT=0}$ values for the years 2040, 2070 and 2100. We coded these three periods/years as variable $\mathrm{time}$ with values $0, 1, 2$ respectively. We use the respective total or mean $RS$ values to calculate the response variable and includes a categorical variable $\mathrm{method}$ with three levels indicating either the direct indicator ($ice$) or indirect indicator with two alternative thresholds ($acc$ or $ess$).

```{r}
valid_methods <- c("ice","ess","acc")
model_data <- model_data %>% 
  filter(method %in% valid_methods) %>% 
  mutate(
    method=droplevels(method),
    collapsed=case_when(
      method %in% "ice" & RS == 1 ~ 1L,
      !(method %in% "ice") & RS >0.99 ~ 1L,
      TRUE ~ 0L
    )
    )
```


## $\beta$ distribution GLMM of $\overline{\mathrm{RS}}$

Given that RS represent a relative measure (proportion between 0 and 1), we use a beta distribution GLMM with logit link function with $y=RS$ for all observations where $RS<1$. Just as the model above, we included fixed effects of scenarios ($\mathrm{scenario}$ with three levels) and $\mathrm{time}$, and nested effect of $\mathrm{method}$ within each assessment unit ($\mathrm{unit}$, 15 levels) and implied nested effects of model within $\mathrm{method}$.

Ok, here are two problems: 
  1. The bioclimatic suitability model perform better in the Andes than outside
  2. For some reason Kilimanjaro is just completely different

The first issue is understandable given the uneven sample sizes, and the 

```{r}
#| echo: true

ggplot(
  model_data %>%
  mutate(unit = factor(unit, unit_order))
) +
  geom_boxplot(
    aes(x=RS, y=unit, color=method, group=interaction(unit,method))
    ) +
    ylab("") +
    xlab("Overall RS")
```

```{r}
#| echo: true

model_data_ss <- model_data %>% 
  filter(RS < 1 & RS > 0, !unit %in% "Kilimanjaro") %>%
  mutate(
    period = factor(time),
    andes = grepl("Peru|Colombia|Ecuador",unit)
  )
glimpse(model_data_ss)
```

We fit the full model, and alternative versions with dispersion model and reduced fixed effects as:

```{r}
#| echo: true

mod_degradation_2way_3nest <- 
  glmmTMB(RS ~ (period * scenario) + (method*andes)  + (1|andes/unit/method), 
    dispformula=~method, 
    data = model_data_ss, 
    family=beta_family,
    REML=FALSE)

mod_degradation_2way_2nest <- 
  glmmTMB(RS ~ (period * scenario) + (method*andes) + (1|unit/method), 
        dispformula=~method, 
        data = model_data_ss, 
        family=beta_family,
        REML=FALSE)

mod_degradation_3way_2nest <- 
  glmmTMB(RS ~ period * scenario * method * andes + (1|unit/method), 
        dispformula=~method, 
        data = model_data_ss, 
        family=beta_family,
        REML=FALSE)

mod_degradation_3way_3nest <- 
  glmmTMB(RS ~ period * scenario * method * andes + (1|andes/unit/method), 
        dispformula=~method, 
        data = model_data_ss, 
        family=beta_family,
        REML=FALSE)
```


The AIC criterion favours the initial specification with all variables and without dispersion model:

```{r}
#| echo: true
bbmle::AICtab(mod_degradation_3way_3nest,
              mod_degradation_3way_2nest,
              mod_degradation_2way_3nest,
              mod_degradation_2way_2nest)
```

### Model diagnostics

Model diagnostics and residual plots look more or less ok, but there is probably some effect of the unequal sample sizes between units, as we are excluding observations with $RS=1$ and these are not evenly distributed among the assessment units.

```{r}
#| echo: true
mod_degradation_simres<-simulateResiduals(mod_degradation_3way_2nest)
plot(mod_degradation_simres)
```
 
### Outliers

When we examine the outliers, these are mostly unexpected low values in the T.G.E. Kilimanjaro, but these are probably related to underlying anomalies in climatic conditions in this region. [In fact, when using the original formulafor the time series of the dynamic ice mass balance model there were some spurious effect of negative RS in this unit. We are using now the conditional formula of RS but there is still some unexpected structure in the residuals.]{.aside}

```{r}
#| eval: true
#| echo: true
mod_degradation_simres$fittedModel$frame %>% slice(outliers(mod_degradation_simres))
```

### Model summary

The summary of the model indicates significant positive effects of time and future scenarios in the magnitude of RS, as expected. For the method variable, the indirect indicator have significant negative effects when compared with the direct indicator, but the effect is larger for the maximum accuracy threshold. We can interpret this to be the lower, more conservative or optimistic bound of RS for this indicator. In general, variability between units is considerably larger than variability between methods, thus we can expect all three methods to reflect general patterns, but will require closer inspection to rule out interaction with the random effects of assessment units.

```{r}
#| echo: true
#| eval: true
#| attr-output: "style='font-size: 0.8em'"
options(width=120)
summary(mod_degradation_3way_2nest)
```


### Random effects

The random effects of the model give us a ranking of the general magnitude of RS for each assessment unit, regardless of the method used:

```{r}
#| eval: true
#| echo: true
rr <- ranef(mod_degradation_3way_2nest)
rr$cond$unit %>% arrange(desc(`(Intercept)`))
```

We see that there are a few large differences in the ranking compared with the model of collapse, most notably in the T.G.E. of Kilimanjaro, but this is likely a result of anomalies in the underlying data.

```{r}
#| eval: true
model_data_ss$pred <- predict(mod_degradation_3way_2nest,type="response")

ggplot(model_data_ss) +
  geom_boxplot(aes(x=pred,y=unit,color=method,group=interaction(unit,method)))
```

## $\beta$ distribution GLMM of $\mathrm{cED}(0.3)$

Given that RS represent a relative measure (proportion between 0 and 1), we use a beta distribution GLMM with logit link function with $y=\mathrm{cED}(0.3)$ for all observations where $\mathrm{cED}(0.3)<1$. Just as the model above, we included fixed effects of scenarios ($\mathrm{scenario}$ with three levels) and $\mathrm{time}$, and nested effect of $\mathrm{method}$ within each assessment unit ($\mathrm{unit}$, 15 levels) and implied nested effects of model within $\mathrm{method}$.

```{r}
#| echo: true

model_data_ss <- cED_model_data %>% 
  filter(
    method %in% valid_methods,
    cED_30>0 & cED_30<1
    ) %>% 
  mutate(
    method=factor(method),
    period = factor(time),
    andes = grepl("Peru|Colombia|Ecuador",unit)
  )
  model_data_ss
```

```{r}
#| echo: true
mod_cED_30_sat <- 
  glmmTMB(cED_30 ~  (method*andes) + period + scenario + (1|andes/unit/method), 
    dispformula = ~ method, 
    data = model_data_ss, 
    family = beta_family,
    REML=FALSE)

mod_cED_30_2way_3nest <- 
  glmmTMB(cED_30 ~ (method*andes) + period + scenario +  (1|unit/method), 
    dispformula=~method, 
    data = model_data_ss, 
    family=beta_family,
    REML=FALSE)

mod_cED_30_2way_2nest <- 
  glmmTMB(cED_30 ~ (method*andes) + period + scenario +  (1|unit), 
        dispformula=~method, 
        data = model_data_ss, 
        family=beta_family,
        REML=FALSE)

mod_cED_30_3way_2nest <- 
  glmmTMB(cED_30 ~ period * scenario + (method*andes) + (1|unit/method), 
        dispformula=~method, 
        data = model_data_ss, 
        family=beta_family,
        REML=FALSE)

mod_cED_30_3way_3nest <- 
  glmmTMB(cED_30 ~ period * scenario + (method*andes) + (1|andes/unit/method), 
        dispformula=~method, 
        data = model_data_ss, 
        family=beta_family,
        REML=FALSE)
```

```{r}
bbmle::AICtab(
  mod_cED_30_sat,
  mod_cED_30_3way_3nest,
  mod_cED_30_3way_2nest,
  mod_cED_30_2way_3nest,
  mod_cED_30_2way_2nest
  )
```

### Model diagnostics

Model diagnostics and residual plots look more or less ok, but there is probably some effect of the unequal sample sizes between units, as we are excluding observations with $RS=1$ and these are not evenly distributed among the assessment units.

```{r}
#| echo: true
mod_cED_simres<-simulateResiduals(mod_cED_30_3way_2nest)
plot(mod_cED_simres)
```

## $\beta$ distribution GLMM of $\mathrm{cED}(0.5)$

Given that RS represent a relative measure (proportion between 0 and 1), we use a beta distribution GLMM with logit link function with $y=\mathrm{cED}(0.5)$ for all observations where $\mathrm{cED}(0.5)<1$. Just as the model above, we included fixed effects of scenarios ($\mathrm{scenario}$ with three levels) and $\mathrm{time}$, and nested effect of $\mathrm{method}$ within each assessment unit ($\mathrm{unit}$, 15 levels) and implied nested effects of model within $\mathrm{method}$.


```{r}
#| echo: true

model_data_ss <- cED_model_data %>% 
  filter(
    method %in% valid_methods,
    cED_50>0 & cED_50<1
    ) %>% 
  mutate(
    method=factor(method),
    period = factor(time),
    andes = grepl("Peru|Colombia|Ecuador",unit)
  )
  glimpse(model_data_ss)
```
## $\beta$ distribution GLMM of $\mathrm{cED}(0.8)$

Given that RS represent a relative measure (proportion between 0 and 1), we use a beta distribution GLMM with logit link function with $y=\mathrm{cED}(0.8)$ for all observations where $\mathrm{cED}(0.8)<1$. Just as the model above, we included fixed effects of scenarios ($\mathrm{scenario}$ with three levels) and $\mathrm{time}$, and nested effect of $\mathrm{method}$ within each assessment unit ($\mathrm{unit}$, 15 levels) and implied nested effects of model within $\mathrm{method}$.


```{r}
#| echo: true

model_data_ss <- cED_model_data %>% 
  filter(
    method %in% valid_methods,
    cED_80>0 & cED_80<1
    ) %>% 
  mutate(
    method=factor(method),
    period = factor(time),
    andes = grepl("Peru|Colombia|Ecuador",unit)
  )
  glimpse(model_data_ss)
```

```{r}
#| echo: true
mod_cED_80_sat <- 
  glmmTMB(cED_80 ~ time * method * scenario * andes + (1|unit/method), 
    dispformula = ~ method, 
    data = model_data_ss, 
    family = beta_family,
    REML=FALSE)

mod_cED_80_2way_3nest <- 
  glmmTMB(cED_80 ~ (period * scenario) + (method*andes)  + (1|andes/unit/method), 
    dispformula=~method, 
    data = model_data_ss, 
    family=beta_family,
    REML=FALSE)

mod_cED_80_2way_2nest <- 
  glmmTMB(cED_80 ~ (period * scenario) + (method*andes) + (1|unit/method), 
        dispformula=~method, 
        data = model_data_ss, 
        family=beta_family,
        REML=FALSE)

mod_cED_80_3way_2nest <- 
  glmmTMB(cED_80 ~ period * scenario * method * andes + (1|unit/method), 
        dispformula=~method, 
        data = model_data_ss, 
        family=beta_family,
        REML=FALSE)

mod_cED_80_3way_3nest <- 
  glmmTMB(cED_80 ~ period * scenario * method * andes + (1|andes/unit/method), 
        dispformula=~method, 
        data = model_data_ss, 
        family=beta_family,
        REML=FALSE)
```

```{r}
bbmle::AICtab(
  mod_cED_80_sat,
  mod_cED_80_3way_3nest,
  mod_cED_80_3way_2nest,
  mod_cED_80_2way_3nest,
  mod_cED_80_2way_2nest
  )
```

### Model diagnostics

Model diagnostics and residual plots look more or less ok, but there is probably some effect of the unequal sample sizes between units, as we are excluding observations with $RS=1$ and these are not evenly distributed among the assessment units.

```{r}
#| echo: true
mod_cED_simres<-simulateResiduals(mod_cED_80_3way_2nest)
plot(mod_cED_simres)
```


## $\beta$ distribution GLMM of $\mathrm{AUC}_{\mathrm{cED}}$

Given that RS represent a relative measure (proportion between 0 and 1), we use a beta distribution GLMM with logit link function with $y=\mathrm{AUC}_{\mathrm{cED}}$ for all observations where $\mathrm{AUC}_{\mathrm{cED}}<1$. Just as the model above, we included fixed effects of scenarios ($\mathrm{scenario}$ with three levels) and $\mathrm{time}$, and nested effect of $\mathrm{method}$ within each assessment unit ($\mathrm{unit}$, 15 levels) and implied nested effects of model within $\mathrm{method}$.
